{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "conf = pyspark.SparkConf().setAppName('WordCount').setMaster('local[*]') # Using all cores in our machine\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Data\n",
    "rdd =sc.textFile('C://spark//spark-3.0.0-bin-hadoop2.7//README.md') # The data will stored in RDD structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Apache Spark',\n",
       " '',\n",
       " 'Spark is a unified analytics engine for large-scale data processing. It provides',\n",
       " 'high-level APIs in Scala, Java, Python, and R, and an optimized engine that',\n",
       " 'supports general computation graphs for data analysis. It also supports a',\n",
       " 'rich set of higher-level tools including Spark SQL for SQL and DataFrames,',\n",
       " 'MLlib for machine learning, GraphX for graph processing,',\n",
       " 'and Structured Streaming for stream processing.',\n",
       " '',\n",
       " '<https://spark.apache.org/>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see first 10 RDD elements \n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to Remove Punctuation and Transform All Words to Lowercase\n",
    "def lower_clean_str(x):\n",
    "    punc='!@#$%^&*<(,){.}`~\":;[]\\+=///>_-'\n",
    "    lowercased_str = x.lower()\n",
    "    for ch in punc:\n",
    "        lowercased_str = lowercased_str.replace(ch,'')\n",
    "    return lowercased_str     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' apache spark',\n",
       " '',\n",
       " 'spark is a unified analytics engine for largescale data processing it provides',\n",
       " 'highlevel apis in scala java python and r and an optimized engine that',\n",
       " 'supports general computation graphs for data analysis it also supports a',\n",
       " 'rich set of higherlevel tools including spark sql for sql and dataframes',\n",
       " 'mllib for machine learning graphx for graph processing',\n",
       " 'and structured streaming for stream processing',\n",
       " '',\n",
       " 'httpssparkapacheorg']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the function on the data\n",
    "rdd = rdd.map(lower_clean_str)\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'apache',\n",
       " 'spark',\n",
       " '',\n",
       " 'spark',\n",
       " 'is',\n",
       " 'a',\n",
       " 'unified',\n",
       " 'analytics',\n",
       " 'engine']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the string by space character.\n",
    "rdd = rdd.flatMap(lambda satir: satir.split(\" \"))\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apache',\n",
       " 'spark',\n",
       " 'spark',\n",
       " 'is',\n",
       " 'a',\n",
       " 'unified',\n",
       " 'analytics',\n",
       " 'engine',\n",
       " 'for',\n",
       " 'largescale']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering to exclude whitespaces.\n",
    "rdd = rdd.filter(lambda x:x!='')\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apache', 1),\n",
       " ('spark', 1),\n",
       " ('spark', 1),\n",
       " ('is', 1),\n",
       " ('a', 1),\n",
       " ('unified', 1),\n",
       " ('analytics', 1),\n",
       " ('engine', 1),\n",
       " ('for', 1),\n",
       " ('largescale', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count each word in the file\n",
    "rdd = rdd.map(lambda word:(word,1))\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1000', 2),\n",
       " ('1000000000', 2),\n",
       " ('1000count', 2),\n",
       " ('a', 10),\n",
       " ('abbreviated', 1),\n",
       " ('about', 1),\n",
       " ('against', 1),\n",
       " ('also', 5),\n",
       " ('alternatively', 1),\n",
       " ('an', 4),\n",
       " ('analysis', 1),\n",
       " ('analytics', 1),\n",
       " ('and', 10),\n",
       " ('apache', 2),\n",
       " ('apis', 1),\n",
       " ('appveyor', 1),\n",
       " ('are', 1),\n",
       " ('at', 2),\n",
       " ('available', 1),\n",
       " ('basic', 1),\n",
       " ('be', 2),\n",
       " ('because', 1),\n",
       " ('binpyspark', 1),\n",
       " ('binrunexample', 3),\n",
       " ('binsparkshell', 1),\n",
       " ('build', 3),\n",
       " ('buildhttpsamplabcsberkeleyedujenkinsjobsparkmastertestsbthadoop27hive23badgeiconhttpsamplabcsberkeleyedujenkinsjobsparkmastertestsbthadoop27hive23',\n",
       "  1),\n",
       " ('buildhttpsimgshieldsioappveyorciapachesoftwarefoundationsparkmastersvg?styleplasticlogoappveyorhttpsciappveyorcomprojectapachesoftwarefoundationspark',\n",
       "  1),\n",
       " ('building', 5),\n",
       " ('buildmvn', 1),\n",
       " ('built', 2),\n",
       " ('can', 6),\n",
       " ('changed', 1),\n",
       " ('class', 3),\n",
       " ('clean', 1),\n",
       " ('cluster', 2),\n",
       " ('comes', 1),\n",
       " ('command', 2),\n",
       " ('computation', 1),\n",
       " ('configuration', 2),\n",
       " ('configure', 1),\n",
       " ('contains', 1),\n",
       " ('contributing', 2),\n",
       " ('contribution', 1),\n",
       " ('core', 1),\n",
       " ('coveragehttpsimgshieldsiobadgedynamicxmlsvg?labelpyspark20coverageurlhttps3a2f2fsparktestgithubio2fpysparkcoveragesitequery2fhtml2fbody2fdiv5b15d2fdiv2fh12fspancolorbbrightgreenstyleplastichttpssparktestgithubiopysparkcoveragesite',\n",
       "  1),\n",
       " ('data', 2),\n",
       " ('dataframes', 1),\n",
       " ('detailed', 2),\n",
       " ('developer', 1),\n",
       " ('developing', 1),\n",
       " ('development', 1),\n",
       " ('devruntests', 1),\n",
       " ('different', 1),\n",
       " ('directory', 1),\n",
       " ('distribution', 1),\n",
       " ('distributions', 1),\n",
       " ('do', 2),\n",
       " ('documentation', 5),\n",
       " ('downloaded', 1),\n",
       " ('dskiptests', 1),\n",
       " ('easiest', 1),\n",
       " ('enabling', 1),\n",
       " ('engine', 2),\n",
       " ('environment', 1),\n",
       " ('example', 5),\n",
       " ('examples', 4),\n",
       " ('file', 1),\n",
       " ('find', 1),\n",
       " ('first', 1),\n",
       " ('following', 2),\n",
       " ('for', 15),\n",
       " ('from', 1),\n",
       " ('general', 2),\n",
       " ('get', 1),\n",
       " ('given', 1),\n",
       " ('graph', 1),\n",
       " ('graphs', 1),\n",
       " ('graphx', 1),\n",
       " ('guidance', 2),\n",
       " ('guide', 1),\n",
       " ('guidehttpssparkapacheorgcontributinghtml', 1),\n",
       " ('guidehttpssparkapacheorgdocslatestconfigurationhtml', 1),\n",
       " ('hadoop', 5),\n",
       " ('hadoopsupported', 1),\n",
       " ('have', 1),\n",
       " ('hdfs', 1),\n",
       " ('help', 1),\n",
       " ('higherlevel', 1),\n",
       " ('highlevel', 1),\n",
       " ('hive', 2),\n",
       " ('how', 3),\n",
       " ('httpssparkapacheorg', 1),\n",
       " ('ide', 1),\n",
       " ('if', 4),\n",
       " ('in', 5),\n",
       " ('including', 4),\n",
       " ('individual', 1),\n",
       " ('info', 1),\n",
       " ('information', 1),\n",
       " ('instance', 1),\n",
       " ('instructions', 1),\n",
       " ('integration', 1),\n",
       " ('interactive', 2),\n",
       " ('is', 7),\n",
       " ('it', 2),\n",
       " ('its', 1),\n",
       " ('java', 1),\n",
       " ('jenkins', 1),\n",
       " ('kubernetes', 1),\n",
       " ('largescale', 1),\n",
       " ('latest', 1),\n",
       " ('learning', 1),\n",
       " ('library', 1),\n",
       " ('local', 1),\n",
       " ('locally', 3),\n",
       " ('localn', 1),\n",
       " ('machine', 1),\n",
       " ('many', 1),\n",
       " ('master', 1),\n",
       " ('mastersparkhost7077', 1),\n",
       " ('mavenhttpsmavenapacheorg', 1),\n",
       " ('mesos', 1),\n",
       " ('mllib', 1),\n",
       " ('module', 1),\n",
       " ('more', 1),\n",
       " ('must', 1),\n",
       " ('n', 1),\n",
       " ('name', 1),\n",
       " ('need', 1),\n",
       " ('no', 1),\n",
       " ('not', 1),\n",
       " ('note', 1),\n",
       " ('of', 5),\n",
       " ('on', 7),\n",
       " ('once', 1),\n",
       " ('one', 2),\n",
       " ('online', 2),\n",
       " ('only', 1),\n",
       " ('optimized', 1),\n",
       " ('or', 3),\n",
       " ('other', 1),\n",
       " ('overview', 1),\n",
       " ('package', 3),\n",
       " ('pagehttpssparkapacheorgdocumentationhtml', 1),\n",
       " ('params', 2),\n",
       " ('particular', 2),\n",
       " ('pi', 1),\n",
       " ('please', 4),\n",
       " ('prebuilt', 1),\n",
       " ('prefer', 1),\n",
       " ('print', 1),\n",
       " ('processing', 3),\n",
       " ('programming', 1),\n",
       " ('programs', 4),\n",
       " ('project', 3),\n",
       " ('protocols', 1),\n",
       " ('provides', 1),\n",
       " ('pyspark', 1),\n",
       " ('python', 4),\n",
       " ('r', 1),\n",
       " ('readme', 1),\n",
       " ('refer', 2),\n",
       " ('requires', 1),\n",
       " ('resourcemanagerskubernetesintegrationtestsreadmemd', 1),\n",
       " ('return', 2),\n",
       " ('review', 1),\n",
       " ('rich', 1),\n",
       " ('run', 9),\n",
       " ('running', 2),\n",
       " ('runs', 1),\n",
       " ('same', 1),\n",
       " ('sample', 1),\n",
       " ('scala', 4),\n",
       " ('see', 3),\n",
       " ('set', 2),\n",
       " ('setup', 1),\n",
       " ('several', 1),\n",
       " ('shell', 4),\n",
       " ('should', 2),\n",
       " ('site', 1),\n",
       " ('spark', 16),\n",
       " ('sparkbuildingspark', 1),\n",
       " ('sparkhttpssparkapacheorgdocslatestbuildingsparkhtml', 1),\n",
       " ('sparkpi', 2),\n",
       " ('sparkrange1000', 2),\n",
       " ('specifying', 1),\n",
       " ('sql', 2),\n",
       " ('start', 1),\n",
       " ('started', 1),\n",
       " ('storage', 1),\n",
       " ('stream', 1),\n",
       " ('streaming', 1),\n",
       " ('structured', 1),\n",
       " ('submit', 1),\n",
       " ('supports', 2),\n",
       " ('systems', 1),\n",
       " ('talk', 1),\n",
       " ('test', 1),\n",
       " ('testing', 1),\n",
       " ('tests', 3),\n",
       " ('testshttpssparkapacheorgdevelopertoolshtmlindividualtests', 1),\n",
       " ('that', 2),\n",
       " ('the', 24),\n",
       " ('them', 1),\n",
       " ('there', 1),\n",
       " ('this', 3),\n",
       " ('thread', 1),\n",
       " ('threads', 1),\n",
       " ('thriftserver', 1),\n",
       " ('through', 1),\n",
       " ('tips', 1),\n",
       " ('to', 18),\n",
       " ('tools', 1),\n",
       " ('toolshttpssparkapacheorgdevelopertoolshtml', 1),\n",
       " ('try', 1),\n",
       " ('unified', 1),\n",
       " ('url', 1),\n",
       " ('usage', 1),\n",
       " ('use', 3),\n",
       " ('useful', 1),\n",
       " ('uses', 1),\n",
       " ('using', 4),\n",
       " ('variable', 1),\n",
       " ('version', 2),\n",
       " ('versions', 2),\n",
       " ('way', 1),\n",
       " ('web', 1),\n",
       " ('when', 1),\n",
       " ('which', 2),\n",
       " ('will', 1),\n",
       " ('with', 3),\n",
       " ('yarn', 2),\n",
       " ('yarnhttpssparkapacheorgdocslatestbuildingsparkhtmlspecifyingthehadoopversionandenablingyarn',\n",
       "  1),\n",
       " ('you', 8),\n",
       " ('your', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using \"reduceByKey()\" to find the frequencies of each word\n",
    "rdd_count = rdd.reduceByKey(lambda x,y:(x+y)).sortByKey()\n",
    "rdd_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, '1000'),\n",
       " (2, '1000000000'),\n",
       " (2, '1000count'),\n",
       " (10, 'a'),\n",
       " (1, 'abbreviated'),\n",
       " (1, 'about'),\n",
       " (1, 'against'),\n",
       " (5, 'also'),\n",
       " (1, 'alternatively'),\n",
       " (4, 'an')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switching (key,val) pairs as (val,key)\n",
    "rdd_count=rdd_count.map(lambda x:(x[1],x[0]))\n",
    "rdd_count.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'abbreviated'),\n",
       " (1, 'about'),\n",
       " (1, 'against'),\n",
       " (1, 'alternatively'),\n",
       " (1, 'analysis'),\n",
       " (1, 'analytics'),\n",
       " (1, 'apis'),\n",
       " (1, 'appveyor'),\n",
       " (1, 'are'),\n",
       " (1, 'available'),\n",
       " (1, 'basic'),\n",
       " (1, 'because'),\n",
       " (1, 'binpyspark'),\n",
       " (1, 'binsparkshell'),\n",
       " (1,\n",
       "  'buildhttpsamplabcsberkeleyedujenkinsjobsparkmastertestsbthadoop27hive23badgeiconhttpsamplabcsberkeleyedujenkinsjobsparkmastertestsbthadoop27hive23'),\n",
       " (1,\n",
       "  'buildhttpsimgshieldsioappveyorciapachesoftwarefoundationsparkmastersvg?styleplasticlogoappveyorhttpsciappveyorcomprojectapachesoftwarefoundationspark'),\n",
       " (1, 'buildmvn'),\n",
       " (1, 'changed'),\n",
       " (1, 'clean'),\n",
       " (1, 'comes'),\n",
       " (1, 'computation'),\n",
       " (1, 'configure'),\n",
       " (1, 'contains'),\n",
       " (1, 'contribution'),\n",
       " (1, 'core'),\n",
       " (1,\n",
       "  'coveragehttpsimgshieldsiobadgedynamicxmlsvg?labelpyspark20coverageurlhttps3a2f2fsparktestgithubio2fpysparkcoveragesitequery2fhtml2fbody2fdiv5b15d2fdiv2fh12fspancolorbbrightgreenstyleplastichttpssparktestgithubiopysparkcoveragesite'),\n",
       " (1, 'dataframes'),\n",
       " (1, 'developer'),\n",
       " (1, 'developing'),\n",
       " (1, 'development')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent words in ascending order\n",
    "rdd_count.sortByKey(True).take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 'the'),\n",
       " (18, 'to'),\n",
       " (16, 'spark'),\n",
       " (15, 'for'),\n",
       " (10, 'a'),\n",
       " (10, 'and'),\n",
       " (9, 'run'),\n",
       " (8, 'you'),\n",
       " (7, 'is'),\n",
       " (7, 'on')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent words in descending order\n",
    "rdd_count.sortByKey(False).take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
